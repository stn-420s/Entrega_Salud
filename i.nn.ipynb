{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura de base de datos\n",
    "df = pd.read_csv('DBs\\df_sel.csv')\n",
    "y = pd.read_csv('DBs\\y.csv')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "y.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>servicio_habilitado</th>\n",
       "      <th>via_ingreso</th>\n",
       "      <th>unidad_estrategica</th>\n",
       "      <th>transfusion_sangre</th>\n",
       "      <th>antibiotico</th>\n",
       "      <th>dx_principal_egreso_capitulo</th>\n",
       "      <th>profesional_especialidad_grd</th>\n",
       "      <th>clasificacion_imc</th>\n",
       "      <th>control_diabetes</th>\n",
       "      <th>tiene_hta</th>\n",
       "      <th>...</th>\n",
       "      <th>mets_-indice_metabolico</th>\n",
       "      <th>vo2_-_maxima_cantidad_de_oxigeno</th>\n",
       "      <th>lipoproteina</th>\n",
       "      <th>trigliceridos</th>\n",
       "      <th>creatinina_1_consulta</th>\n",
       "      <th>tasa_de_filtracion_glomerular_tfg</th>\n",
       "      <th>hormona_estimulante_de_la_tiroides_(tsh)</th>\n",
       "      <th>creatinina_2_consulta</th>\n",
       "      <th>numero_diagnosticos</th>\n",
       "      <th>edad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187534</td>\n",
       "      <td>0.187535</td>\n",
       "      <td>0.375595</td>\n",
       "      <td>0.068970</td>\n",
       "      <td>0.073067</td>\n",
       "      <td>0.214658</td>\n",
       "      <td>0.141486</td>\n",
       "      <td>0.065060</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.765432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147796</td>\n",
       "      <td>0.147795</td>\n",
       "      <td>0.522063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045503</td>\n",
       "      <td>0.099598</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.864198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.209841</td>\n",
       "      <td>0.209841</td>\n",
       "      <td>0.242063</td>\n",
       "      <td>0.088553</td>\n",
       "      <td>0.051827</td>\n",
       "      <td>0.213859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020546</td>\n",
       "      <td>0.205458</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085817</td>\n",
       "      <td>0.072218</td>\n",
       "      <td>0.206353</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.106024</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.802469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.627776</td>\n",
       "      <td>0.627775</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.108495</td>\n",
       "      <td>0.068819</td>\n",
       "      <td>0.525542</td>\n",
       "      <td>0.699253</td>\n",
       "      <td>0.062651</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.283951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230516</td>\n",
       "      <td>0.230517</td>\n",
       "      <td>0.533770</td>\n",
       "      <td>0.320374</td>\n",
       "      <td>0.050127</td>\n",
       "      <td>0.274256</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069880</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.410322</td>\n",
       "      <td>0.410321</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050468</td>\n",
       "      <td>0.095157</td>\n",
       "      <td>0.146615</td>\n",
       "      <td>0.076431</td>\n",
       "      <td>0.094779</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.827160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040426</td>\n",
       "      <td>0.404256</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061847</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.679012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506069</td>\n",
       "      <td>0.506070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.950617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.406412</td>\n",
       "      <td>0.406413</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066019</td>\n",
       "      <td>0.041631</td>\n",
       "      <td>0.330970</td>\n",
       "      <td>0.028795</td>\n",
       "      <td>0.048193</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.802469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1473 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      servicio_habilitado  via_ingreso  unidad_estrategica  \\\n",
       "0                0.666667          0.5            0.333333   \n",
       "1                0.666667          0.5            0.333333   \n",
       "2                0.666667          1.0            0.333333   \n",
       "3                0.666667          1.0            0.333333   \n",
       "4                0.666667          1.0            0.333333   \n",
       "...                   ...          ...                 ...   \n",
       "1468             0.666667          1.0            0.333333   \n",
       "1469             1.000000          1.0            1.000000   \n",
       "1470             0.666667          1.0            0.333333   \n",
       "1471             0.666667          1.0            0.333333   \n",
       "1472             1.000000          1.0            1.000000   \n",
       "\n",
       "      transfusion_sangre  antibiotico  dx_principal_egreso_capitulo  \\\n",
       "0                    0.0          0.0                        0.0625   \n",
       "1                    0.0          0.0                        0.0625   \n",
       "2                    0.0          0.0                        0.3750   \n",
       "3                    0.0          0.0                        0.4375   \n",
       "4                    0.0          1.0                        0.5000   \n",
       "...                  ...          ...                           ...   \n",
       "1468                 0.0          1.0                        0.4375   \n",
       "1469                 0.0          0.0                        0.9375   \n",
       "1470                 0.0          0.0                        0.7500   \n",
       "1471                 0.0          0.0                        0.3750   \n",
       "1472                 0.0          0.0                        0.3750   \n",
       "\n",
       "      profesional_especialidad_grd  clasificacion_imc  control_diabetes  \\\n",
       "0                         0.586207           0.666667          1.000000   \n",
       "1                         0.586207           1.000000          0.000000   \n",
       "2                         0.586207           0.333333          1.000000   \n",
       "3                         0.068966           1.000000          1.000000   \n",
       "4                         0.482759           0.666667          0.333333   \n",
       "...                            ...                ...               ...   \n",
       "1468                      0.068966           0.333333          0.666667   \n",
       "1469                      0.655172           0.333333          0.333333   \n",
       "1470                      0.241379           0.666667          0.000000   \n",
       "1471                      0.586207           0.000000          0.333333   \n",
       "1472                      0.551724           0.333333          0.333333   \n",
       "\n",
       "      tiene_hta  ...  mets_-indice_metabolico  \\\n",
       "0           1.0  ...                 0.187534   \n",
       "1           0.0  ...                 0.147796   \n",
       "2           1.0  ...                 0.209841   \n",
       "3           1.0  ...                 0.020546   \n",
       "4           1.0  ...                 0.627776   \n",
       "...         ...  ...                      ...   \n",
       "1468        1.0  ...                 0.230516   \n",
       "1469        1.0  ...                 0.410322   \n",
       "1470        1.0  ...                 0.040426   \n",
       "1471        1.0  ...                 0.506069   \n",
       "1472        0.0  ...                 0.406412   \n",
       "\n",
       "      vo2_-_maxima_cantidad_de_oxigeno  lipoproteina  trigliceridos  \\\n",
       "0                             0.187535      0.375595       0.068970   \n",
       "1                             0.147795      0.522063       0.000000   \n",
       "2                             0.209841      0.242063       0.088553   \n",
       "3                             0.205458      0.000000       0.085817   \n",
       "4                             0.627775      0.000000       0.108495   \n",
       "...                                ...           ...            ...   \n",
       "1468                          0.230517      0.533770       0.320374   \n",
       "1469                          0.410321      0.000000       0.050468   \n",
       "1470                          0.404256      0.000000       0.000000   \n",
       "1471                          0.506070      0.000000       0.000000   \n",
       "1472                          0.406413      0.000000       0.066019   \n",
       "\n",
       "      creatinina_1_consulta  tasa_de_filtracion_glomerular_tfg  \\\n",
       "0                  0.073067                           0.214658   \n",
       "1                  0.000000                           0.000000   \n",
       "2                  0.051827                           0.213859   \n",
       "3                  0.072218                           0.206353   \n",
       "4                  0.068819                           0.525542   \n",
       "...                     ...                                ...   \n",
       "1468               0.050127                           0.274256   \n",
       "1469               0.095157                           0.146615   \n",
       "1470               0.000000                           0.000000   \n",
       "1471               0.000000                           0.000000   \n",
       "1472               0.041631                           0.330970   \n",
       "\n",
       "      hormona_estimulante_de_la_tiroides_(tsh)  creatinina_2_consulta  \\\n",
       "0                                     0.141486               0.065060   \n",
       "1                                     0.045503               0.099598   \n",
       "2                                     0.000000               0.000000   \n",
       "3                                     0.005332               0.106024   \n",
       "4                                     0.699253               0.062651   \n",
       "...                                        ...                    ...   \n",
       "1468                                  0.000000               0.069880   \n",
       "1469                                  0.076431               0.094779   \n",
       "1470                                  0.000000               0.061847   \n",
       "1471                                  0.000000               0.000000   \n",
       "1472                                  0.028795               0.048193   \n",
       "\n",
       "      numero_diagnosticos      edad  \n",
       "0                0.083333  0.765432  \n",
       "1                0.027778  0.864198  \n",
       "2                0.000000  0.777778  \n",
       "3                0.000000  0.802469  \n",
       "4                0.000000  0.283951  \n",
       "...                   ...       ...  \n",
       "1468             0.055556  0.666667  \n",
       "1469             0.000000  0.827160  \n",
       "1470             0.000000  0.679012  \n",
       "1471             0.000000  0.950617  \n",
       "1472             0.000000  0.802469  \n",
       "\n",
       "[1473 rows x 40 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tiempo_estancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77.719108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>302.528029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>168.615411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90.240822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>245.486805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>133.301420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>23.346871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>62.268748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>91.969748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>46.309283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1473 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      tiempo_estancia\n",
       "0           77.719108\n",
       "1          302.528029\n",
       "2          168.615411\n",
       "3           90.240822\n",
       "4          245.486805\n",
       "...               ...\n",
       "1468       133.301420\n",
       "1469        23.346871\n",
       "1470        62.268748\n",
       "1471        91.969748\n",
       "1472        46.309283\n",
       "\n",
       "[1473 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Supongamos que tienes un DataFrame 'data' con una columna llamada 'variable_a_escalar'\n",
    "scaler = MinMaxScaler()\n",
    "y['tiempo_estancia'] = scaler.fit_transform(y[['tiempo_estancia']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(df,y,test_size=0.5,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tiempo_estancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>0.441172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>0.047244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>0.006548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>0.026695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.042809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>0.002728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>0.180832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>0.003738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0.017451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>0.125230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>736 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      tiempo_estancia\n",
       "661          0.441172\n",
       "588          0.047244\n",
       "907          0.006548\n",
       "751          0.026695\n",
       "62           0.042809\n",
       "...               ...\n",
       "763          0.002728\n",
       "835          0.180832\n",
       "1216         0.003738\n",
       "559          0.017451\n",
       "684          0.125230\n",
       "\n",
       "[736 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>servicio_habilitado</th>\n",
       "      <th>via_ingreso</th>\n",
       "      <th>unidad_estrategica</th>\n",
       "      <th>transfusion_sangre</th>\n",
       "      <th>antibiotico</th>\n",
       "      <th>dx_principal_egreso_capitulo</th>\n",
       "      <th>profesional_especialidad_grd</th>\n",
       "      <th>clasificacion_imc</th>\n",
       "      <th>control_diabetes</th>\n",
       "      <th>tiene_hta</th>\n",
       "      <th>...</th>\n",
       "      <th>mets_-indice_metabolico</th>\n",
       "      <th>vo2_-_maxima_cantidad_de_oxigeno</th>\n",
       "      <th>lipoproteina</th>\n",
       "      <th>trigliceridos</th>\n",
       "      <th>creatinina_1_consulta</th>\n",
       "      <th>tasa_de_filtracion_glomerular_tfg</th>\n",
       "      <th>hormona_estimulante_de_la_tiroides_(tsh)</th>\n",
       "      <th>creatinina_2_consulta</th>\n",
       "      <th>numero_diagnosticos</th>\n",
       "      <th>edad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.522719</td>\n",
       "      <td>0.522719</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.518519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.271758</td>\n",
       "      <td>0.271758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.294672</td>\n",
       "      <td>0.061172</td>\n",
       "      <td>0.255734</td>\n",
       "      <td>0.095627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.679012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.552511</td>\n",
       "      <td>0.552510</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.096472</td>\n",
       "      <td>0.169924</td>\n",
       "      <td>0.086148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.679012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.236732</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.317460</td>\n",
       "      <td>0.044636</td>\n",
       "      <td>0.084962</td>\n",
       "      <td>0.102516</td>\n",
       "      <td>0.150729</td>\n",
       "      <td>0.050602</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.938272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.445735</td>\n",
       "      <td>0.445735</td>\n",
       "      <td>0.337302</td>\n",
       "      <td>0.073434</td>\n",
       "      <td>0.084962</td>\n",
       "      <td>0.169864</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.802469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.207628</td>\n",
       "      <td>0.207627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097408</td>\n",
       "      <td>0.051827</td>\n",
       "      <td>0.258931</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.814815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.212362</td>\n",
       "      <td>0.212362</td>\n",
       "      <td>0.186508</td>\n",
       "      <td>0.081353</td>\n",
       "      <td>0.063721</td>\n",
       "      <td>0.193321</td>\n",
       "      <td>0.237469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.765432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.286088</td>\n",
       "      <td>0.286089</td>\n",
       "      <td>0.174762</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088360</td>\n",
       "      <td>0.146754</td>\n",
       "      <td>0.113402</td>\n",
       "      <td>0.081124</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.753086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186281</td>\n",
       "      <td>0.186280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087185</td>\n",
       "      <td>0.153781</td>\n",
       "      <td>0.075445</td>\n",
       "      <td>0.144685</td>\n",
       "      <td>0.142972</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.851852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220182</td>\n",
       "      <td>0.220182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.703704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>736 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      servicio_habilitado  via_ingreso  unidad_estrategica  \\\n",
       "661              0.666667          1.0            0.333333   \n",
       "588              0.666667          0.5            0.333333   \n",
       "907              0.333333          0.0            0.000000   \n",
       "751              0.666667          1.0            0.333333   \n",
       "62               0.666667          0.0            0.333333   \n",
       "...                   ...          ...                 ...   \n",
       "763              1.000000          1.0            1.000000   \n",
       "835              0.666667          1.0            0.333333   \n",
       "1216             0.666667          0.0            0.333333   \n",
       "559              0.666667          1.0            0.333333   \n",
       "684              0.666667          1.0            0.333333   \n",
       "\n",
       "      transfusion_sangre  antibiotico  dx_principal_egreso_capitulo  \\\n",
       "661                  0.0          1.0                        0.6250   \n",
       "588                  0.0          1.0                        0.7500   \n",
       "907                  0.0          0.0                        0.4375   \n",
       "751                  0.0          0.0                        0.9375   \n",
       "62                   0.0          1.0                        0.6875   \n",
       "...                  ...          ...                           ...   \n",
       "763                  0.0          1.0                        0.7500   \n",
       "835                  0.0          0.0                        0.7500   \n",
       "1216                 0.0          0.0                        0.5000   \n",
       "559                  0.0          0.0                        0.0625   \n",
       "684                  1.0          0.0                        1.0000   \n",
       "\n",
       "      profesional_especialidad_grd  clasificacion_imc  control_diabetes  \\\n",
       "661                       0.172414           0.666667          0.000000   \n",
       "588                       0.586207           1.000000          1.000000   \n",
       "907                       0.068966           0.333333          0.333333   \n",
       "751                       0.793103           0.333333          0.333333   \n",
       "62                        0.586207           0.333333          0.333333   \n",
       "...                            ...                ...               ...   \n",
       "763                       0.551724           1.000000          1.000000   \n",
       "835                       0.586207           1.000000          0.666667   \n",
       "1216                      0.379310           1.000000          0.000000   \n",
       "559                       0.586207           1.000000          1.000000   \n",
       "684                       0.068966           0.666667          0.333333   \n",
       "\n",
       "      tiene_hta  ...  mets_-indice_metabolico  \\\n",
       "661         1.0  ...                 0.522719   \n",
       "588         1.0  ...                 0.271758   \n",
       "907         1.0  ...                 0.552511   \n",
       "751         1.0  ...                 0.236732   \n",
       "62          1.0  ...                 0.445735   \n",
       "...         ...  ...                      ...   \n",
       "763         1.0  ...                 0.207628   \n",
       "835         1.0  ...                 0.212362   \n",
       "1216        1.0  ...                 0.286088   \n",
       "559         1.0  ...                 0.186281   \n",
       "684         1.0  ...                 0.220182   \n",
       "\n",
       "      vo2_-_maxima_cantidad_de_oxigeno  lipoproteina  trigliceridos  \\\n",
       "661                           0.522719      0.000000       0.000000   \n",
       "588                           0.271758      0.000000       0.294672   \n",
       "907                           0.552510      0.619048       0.096472   \n",
       "751                           0.000024      0.317460       0.044636   \n",
       "62                            0.445735      0.337302       0.073434   \n",
       "...                                ...           ...            ...   \n",
       "763                           0.207627      0.000000       0.097408   \n",
       "835                           0.212362      0.186508       0.081353   \n",
       "1216                          0.286089      0.174762       0.000000   \n",
       "559                           0.186280      0.000000       0.087185   \n",
       "684                           0.220182      0.000000       0.000000   \n",
       "\n",
       "      creatinina_1_consulta  tasa_de_filtracion_glomerular_tfg  \\\n",
       "661                0.000000                           0.000000   \n",
       "588                0.061172                           0.255734   \n",
       "907                0.169924                           0.086148   \n",
       "751                0.084962                           0.102516   \n",
       "62                 0.084962                           0.169864   \n",
       "...                     ...                                ...   \n",
       "763                0.051827                           0.258931   \n",
       "835                0.063721                           0.193321   \n",
       "1216               0.088360                           0.146754   \n",
       "559                0.153781                           0.075445   \n",
       "684                0.000000                           0.000000   \n",
       "\n",
       "      hormona_estimulante_de_la_tiroides_(tsh)  creatinina_2_consulta  \\\n",
       "661                                   0.000000               0.000000   \n",
       "588                                   0.095627               0.000000   \n",
       "907                                   0.000000               0.000000   \n",
       "751                                   0.150729               0.050602   \n",
       "62                                    0.000000               0.000000   \n",
       "...                                        ...                    ...   \n",
       "763                                   0.103448               0.000000   \n",
       "835                                   0.237469               0.000000   \n",
       "1216                                  0.113402               0.081124   \n",
       "559                                   0.144685               0.142972   \n",
       "684                                   0.000000               0.000000   \n",
       "\n",
       "      numero_diagnosticos      edad  \n",
       "661              0.000000  0.518519  \n",
       "588              0.083333  0.679012  \n",
       "907              0.000000  0.679012  \n",
       "751              0.000000  0.938272  \n",
       "62               0.000000  0.802469  \n",
       "...                   ...       ...  \n",
       "763              0.000000  0.814815  \n",
       "835              0.000000  0.765432  \n",
       "1216             0.138889  0.753086  \n",
       "559              0.000000  0.851852  \n",
       "684              0.000000  0.703704  \n",
       "\n",
       "[736 rows x 40 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 2s 31ms/step - loss: 0.0135 - val_loss: 0.0084\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0075\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 0.0070\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0077 - val_loss: 0.0069\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0072 - val_loss: 0.0068\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0071 - val_loss: 0.0065\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0067 - val_loss: 0.0064\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0063\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0062 - val_loss: 0.0063\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0061 - val_loss: 0.0063\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0059 - val_loss: 0.0062\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0057 - val_loss: 0.0061\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0055 - val_loss: 0.0060\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0054 - val_loss: 0.0062\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0053 - val_loss: 0.0062\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0051 - val_loss: 0.0060\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0051 - val_loss: 0.0059\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0050 - val_loss: 0.0061\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0048 - val_loss: 0.0060\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0048 - val_loss: 0.0062\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0047 - val_loss: 0.0060\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0045 - val_loss: 0.0061\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0046 - val_loss: 0.0060\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0044 - val_loss: 0.0062\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0044 - val_loss: 0.0060\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0042 - val_loss: 0.0061\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0042 - val_loss: 0.0063\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0061\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0062\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0038 - val_loss: 0.0061\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0038 - val_loss: 0.0062\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0037 - val_loss: 0.0062\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0062\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0037 - val_loss: 0.0064\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0035 - val_loss: 0.0063\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0034 - val_loss: 0.0064\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0034 - val_loss: 0.0063\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.0034 - val_loss: 0.0063\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0032 - val_loss: 0.0064\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0065\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0032 - val_loss: 0.0064\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0031 - val_loss: 0.0064\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0031 - val_loss: 0.0066\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0031 - val_loss: 0.0065\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0029 - val_loss: 0.0066\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0030 - val_loss: 0.0067\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0029 - val_loss: 0.0067\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0029 - val_loss: 0.0067\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0028 - val_loss: 0.0067\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0027 - val_loss: 0.0069\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0027 - val_loss: 0.0071\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0027 - val_loss: 0.0067\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 0.0071\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0026 - val_loss: 0.0070\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0026 - val_loss: 0.0072\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0026 - val_loss: 0.0069\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0024 - val_loss: 0.0070\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0024 - val_loss: 0.0071\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0024 - val_loss: 0.0072\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0024 - val_loss: 0.0071\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0024 - val_loss: 0.0074\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0025 - val_loss: 0.0072\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0023 - val_loss: 0.0074\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0023 - val_loss: 0.0074\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 0.0077\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.0023 - val_loss: 0.0075\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0022 - val_loss: 0.0076\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0022 - val_loss: 0.0075\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0022 - val_loss: 0.0076\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0021 - val_loss: 0.0077\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0021 - val_loss: 0.0079\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0021 - val_loss: 0.0078\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0020 - val_loss: 0.0079\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0020 - val_loss: 0.0081\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0021 - val_loss: 0.0079\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0020 - val_loss: 0.0081\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 0.0080\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 0.0081\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 0.0083\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 0.0081\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.0019 - val_loss: 0.0082\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0019 - val_loss: 0.0083\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 0.0081\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 0.0083\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0083\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0019 - val_loss: 0.0084\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0084\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.0085\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0087\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0087\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0086\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0018 - val_loss: 0.0087\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0017 - val_loss: 0.0087\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 0.0090\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0090\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0088\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0087\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 0.0088\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 0.0090\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2613925f580>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Crear el modelo de regresión\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Agregar capas a tu modelo\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(units=32, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(layers.Dense(units=16, activation='relu'))\n",
    "model.add(layers.Dense(units=1, activation='linear'))\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')  # Puedes cambiar el optimizador y la función de pérdida según tus necesidades\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_1620\\2079449729.py:4: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import RandomSearch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_tuner_directory\\regression_hyperparameter_tuning\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "# Define una función para construir el modelo\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Dense(units=hp.Int('units_1', min_value=16, max_value=128, step=16), activation=hp.Choice('activation_1', values=['relu', 'tanh']), input_dim=X_train.shape[1]))\n",
    "    model.add(layers.Dense(units=hp.Int('units_2', min_value=16, max_value=128, step=16), activation=hp.Choice('activation_2', values=['relu', 'tanh'])))\n",
    "    model.add(layers.Dense(units=1, activation='linear'))\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp.Choice('learning_rate', values=[0.001, 0.01, 0.1])),\n",
    "                  loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Inicializa el sintonizador de búsqueda aleatoria\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=10,  # Número de combinaciones a probar\n",
    "    directory='my_tuner_directory',  # Directorio para guardar resultados\n",
    "    project_name='regression_hyperparameter_tuning'  # Nombre del proyecto\n",
    ")\n",
    "\n",
    "# Realiza la búsqueda aleatoria de hiperparámetros\n",
    "tuner.search(X_train, y_train, epochs=100, validation_data=(X_test, y_test))\n",
    "\n",
    "# Obtiene el mejor modelo\n",
    "best_model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.sequential.Sequential at 0x2613cfade70>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros:\n",
      "Unidades 1: 32\n",
      "Activación 1: relu\n",
      "Unidades 2: 80\n",
      "Activación 2: tanh\n",
      "Tasa de aprendizaje: 0.01\n"
     ]
    }
   ],
   "source": [
    "best_hyperparameters = tuner.get_best_hyperparameters(1)[0]\n",
    "\n",
    "print(\"Mejores hiperparámetros:\")\n",
    "print(\"Unidades 1:\", best_hyperparameters.get('units_1'))\n",
    "print(\"Activación 1:\", best_hyperparameters.get('activation_1'))\n",
    "print(\"Unidades 2:\", best_hyperparameters.get('units_2'))\n",
    "print(\"Activación 2:\", best_hyperparameters.get('activation_2'))\n",
    "print(\"Tasa de aprendizaje:\", best_hyperparameters.get('learning_rate'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Crea el modelo utilizando los mejores hiperparámetros\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(units=32, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(layers.Dense(units=80, activation='relu'))\n",
    "model.add(layers.Dense(units=1, activation='linear'))\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01), loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 5ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "Train - R^2: -6.172788256424513\n",
      "Train - MAE: 495.40566715304345\n",
      "Train - RMSE: 557.4433585337005\n",
      "Test - R^2: -7.406592732596772\n",
      "Test - MAE: 494.11215934303624\n",
      "Test - RMSE: 551.1719705005003\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "# Realizar predicciones en el conjunto de entrenamiento\n",
    "y_pred_train = model.predict(X_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "# Desescalar los valores predichos y los valores reales\n",
    "y_train_descaled = scaler.inverse_transform(y_train)\n",
    "y_pred_train_descaled = scaler.inverse_transform(y_pred_train)\n",
    "\n",
    "y_test_descaled = scaler.inverse_transform(y_test)\n",
    "y_pred_test_descaled = scaler.inverse_transform(y_pred_test)\n",
    "\n",
    "# Calcular métricas R^2, MAE y RMSE para el conjunto de entrenamiento\n",
    "r2_train = r2_score(y_train_descaled, y_pred_train_descaled)\n",
    "mae_train = mean_absolute_error(y_train_descaled, y_pred_train_descaled)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train_descaled, y_pred_train_descaled))\n",
    "\n",
    "# Calcular métricas R^2, MAE y RMSE para el conjunto de prueba\n",
    "r2_test = r2_score(y_test_descaled, y_pred_test_descaled)\n",
    "mae_test = mean_absolute_error(y_test_descaled, y_pred_test_descaled)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test_descaled, y_pred_test_descaled))\n",
    "\n",
    "# Imprimir los resultados para el conjunto de entrenamiento\n",
    "print(\"Train - R^2:\", r2_train)\n",
    "print(\"Train - MAE:\", mae_train)\n",
    "print(\"Train - RMSE:\", rmse_train)\n",
    "\n",
    "# Imprimir los resultados para el conjunto de prueba\n",
    "print(\"Test - R^2:\", r2_test)\n",
    "print(\"Test - MAE:\", mae_test)\n",
    "print(\"Test - RMSE:\", rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "37/37 [==============================] - 1s 3ms/step - loss: 0.0115\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0083\n",
      "Epoch 3/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0083\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0082\n",
      "Epoch 5/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0081\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0080\n",
      "Epoch 7/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0078\n",
      "Epoch 8/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0076\n",
      "Epoch 9/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0073\n",
      "Epoch 10/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0071\n",
      "Epoch 11/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0066\n",
      "Epoch 12/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0064\n",
      "Epoch 13/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0063\n",
      "Epoch 14/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0061\n",
      "Epoch 15/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0061\n",
      "Epoch 16/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0060\n",
      "Epoch 17/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0059\n",
      "Epoch 18/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0059\n",
      "Epoch 19/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0058\n",
      "Epoch 20/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0059\n",
      "Epoch 21/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0058\n",
      "Epoch 22/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0059\n",
      "Epoch 23/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0058\n",
      "Epoch 24/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0059\n",
      "Epoch 25/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0057\n",
      "Epoch 26/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0058\n",
      "Epoch 27/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0058\n",
      "Epoch 28/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0057\n",
      "Epoch 29/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0058\n",
      "Epoch 30/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0057\n",
      "Epoch 31/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0057\n",
      "Epoch 32/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0056\n",
      "Epoch 33/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0057\n",
      "Epoch 34/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0056\n",
      "Epoch 35/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0056\n",
      "Epoch 36/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0057\n",
      "Epoch 37/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0056\n",
      "Epoch 38/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0056\n",
      "Epoch 39/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0056\n",
      "Epoch 40/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0055\n",
      "Epoch 41/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0056\n",
      "Epoch 42/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0055\n",
      "Epoch 43/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0054\n",
      "Epoch 44/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0055\n",
      "Epoch 45/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0054\n",
      "Epoch 46/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0055\n",
      "Epoch 47/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0055\n",
      "Epoch 48/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0054\n",
      "Epoch 49/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0054\n",
      "Epoch 50/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0054\n",
      "Epoch 51/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0054\n",
      "Epoch 52/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0054\n",
      "Epoch 53/100\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0054\n",
      "Epoch 54/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0053\n",
      "Epoch 55/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0055\n",
      "Epoch 56/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0054\n",
      "Epoch 57/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0054\n",
      "Epoch 58/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0053\n",
      "Epoch 59/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0055\n",
      "Epoch 60/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0055\n",
      "Epoch 61/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0053\n",
      "Epoch 62/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0053\n",
      "Epoch 63/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0053\n",
      "Epoch 64/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0053\n",
      "Epoch 65/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0053\n",
      "Epoch 66/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0055\n",
      "Epoch 67/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0052\n",
      "Epoch 68/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0053\n",
      "Epoch 69/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0053\n",
      "Epoch 70/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0052\n",
      "Epoch 71/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0052\n",
      "Epoch 72/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0052\n",
      "Epoch 73/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0053\n",
      "Epoch 74/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0053\n",
      "Epoch 75/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0052\n",
      "Epoch 76/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0053\n",
      "Epoch 77/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0052\n",
      "Epoch 78/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0052\n",
      "Epoch 79/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0052\n",
      "Epoch 80/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0052\n",
      "Epoch 81/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0051\n",
      "Epoch 82/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0051\n",
      "Epoch 83/100\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0051\n",
      "Epoch 84/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0051\n",
      "Epoch 85/100\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0052\n",
      "Epoch 86/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0051\n",
      "Epoch 87/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.0053\n",
      "Epoch 88/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0050\n",
      "Epoch 89/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0051\n",
      "Epoch 90/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0051\n",
      "Epoch 91/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0050\n",
      "Epoch 92/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0050\n",
      "Epoch 93/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0050\n",
      "Epoch 94/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0051\n",
      "Epoch 95/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0049\n",
      "Epoch 96/100\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.0049\n",
      "Epoch 97/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0050\n",
      "Epoch 98/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0050\n",
      "Epoch 99/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0050\n",
      "Epoch 100/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2613d196680>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    " \n",
    "# create ANN model\n",
    "model = Sequential()\n",
    " \n",
    "# Defining the Input layer and FIRST hidden layer, both are same!\n",
    "model.add(Dense(units=5, input_dim=40, kernel_initializer='normal', activation='relu'))\n",
    " \n",
    "# Defining the Second layer of the model\n",
    "# after the first layer we don't have to specify input_dim as keras configure it automatically\n",
    "model.add(Dense(units=5, kernel_initializer='normal', activation='tanh'))\n",
    " \n",
    "# The output neuron is a single fully connected node \n",
    "# Since we will be predicting a single number\n",
    "model.add(Dense(1, kernel_initializer='normal'))\n",
    " \n",
    "# Compiling the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    " \n",
    "# Fitting the ANN to the Training set\n",
    "model.fit(X_train, y_train ,batch_size = 20, epochs = 100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 3ms/step\n",
      "1 Parameters: batch_size: 5 - epochs: 5 Accuracy: -225.6585037443835\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "2 Parameters: batch_size: 5 - epochs: 10 Accuracy: -142.11051479978508\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "3 Parameters: batch_size: 5 - epochs: 50 Accuracy: -84.94659240126654\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "4 Parameters: batch_size: 5 - epochs: 100 Accuracy: -60.25166242624249\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "5 Parameters: batch_size: 5 - epochs: 200 Accuracy: -119.6594801427438\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "6 Parameters: batch_size: 10 - epochs: 5 Accuracy: -225.63818882616766\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "7 Parameters: batch_size: 10 - epochs: 10 Accuracy: -139.7606507893863\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "8 Parameters: batch_size: 10 - epochs: 50 Accuracy: -56.56035198512333\n",
      "24/24 [==============================] - 0s 6ms/step\n",
      "9 Parameters: batch_size: 10 - epochs: 100 Accuracy: -41.38594781937894\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "10 Parameters: batch_size: 10 - epochs: 200 Accuracy: -59.176560091256704\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "11 Parameters: batch_size: 15 - epochs: 5 Accuracy: -243.13174458993598\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "12 Parameters: batch_size: 15 - epochs: 10 Accuracy: -171.34292601916502\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "13 Parameters: batch_size: 15 - epochs: 50 Accuracy: -90.45638606254099\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "14 Parameters: batch_size: 15 - epochs: 100 Accuracy: -53.3568552428263\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "15 Parameters: batch_size: 15 - epochs: 200 Accuracy: -80.16533784956428\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "16 Parameters: batch_size: 20 - epochs: 5 Accuracy: -230.74497273080732\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "17 Parameters: batch_size: 20 - epochs: 10 Accuracy: -132.50668523734083\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "18 Parameters: batch_size: 20 - epochs: 50 Accuracy: -95.73695181195617\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "19 Parameters: batch_size: 20 - epochs: 100 Accuracy: -57.20701376101502\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "20 Parameters: batch_size: 20 - epochs: 200 Accuracy: -64.09620876407686\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "21 Parameters: batch_size: 50 - epochs: 5 Accuracy: -221.41766421882318\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "22 Parameters: batch_size: 50 - epochs: 10 Accuracy: -203.57405286046526\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "23 Parameters: batch_size: 50 - epochs: 50 Accuracy: -87.35029418129787\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "24 Parameters: batch_size: 50 - epochs: 100 Accuracy: -69.33730584793426\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "25 Parameters: batch_size: 50 - epochs: 200 Accuracy: -60.42533340915381\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "26 Parameters: batch_size: 100 - epochs: 5 Accuracy: -262.58899190573413\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "27 Parameters: batch_size: 100 - epochs: 10 Accuracy: -231.34737855098888\n",
      "24/24 [==============================] - 0s 2ms/step\n",
      "28 Parameters: batch_size: 100 - epochs: 50 Accuracy: -98.72314007204727\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "29 Parameters: batch_size: 100 - epochs: 100 Accuracy: -107.55005331969573\n",
      "24/24 [==============================] - 0s 3ms/step\n",
      "30 Parameters: batch_size: 100 - epochs: 200 Accuracy: -70.5803968218369\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Defining a function to find the best parameters for ANN\n",
    "def FunctionFindBestParams(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    # Defining the list of hyper parameters to try\n",
    "    batch_size_list = [5, 10, 15, 20,50,100]\n",
    "    epoch_list = [5, 10, 50, 100,200]\n",
    "    \n",
    "    SearchResultsData = pd.DataFrame(columns=['TrialNumber', 'Parameters', 'Accuracy'])\n",
    "    \n",
    "    # Initializing the trials\n",
    "    TrialNumber = 0\n",
    "    \n",
    "    for batch_size_trial in batch_size_list:\n",
    "        for epochs_trial in epoch_list:\n",
    "            TrialNumber += 1\n",
    "            # Create an ANN model\n",
    "            model = Sequential()\n",
    "            \n",
    "            # Defining the first layer of the model\n",
    "            model.add(Dense(units=5, input_dim=X_train.shape[1], kernel_initializer='normal', activation='relu'))\n",
    " \n",
    "            # Defining the second layer of the model\n",
    "            model.add(Dense(units=5, kernel_initializer='normal', activation='relu'))\n",
    " \n",
    "            # The output neuron is a single fully connected node \n",
    "            # Since we will be predicting a single number\n",
    "            model.add(Dense(1, kernel_initializer='normal'))\n",
    " \n",
    "            # Compiling the model\n",
    "            model.compile(loss='mean_squared_error', optimizer='adam')\n",
    " \n",
    "            # Fitting the ANN to the training set\n",
    "            model.fit(X_train, y_train, batch_size=batch_size_trial, epochs=epochs_trial, verbose=0)\n",
    " \n",
    "            MAPE = np.mean(100 * (np.abs(y_test - model.predict(X_test)) / y_test))\n",
    "            \n",
    "            # Printing the results of the current iteration\n",
    "            print(TrialNumber, 'Parameters:', 'batch_size:', batch_size_trial, '-', 'epochs:', epochs_trial, 'Accuracy:', 100 - MAPE)\n",
    "            \n",
    "            # Append the results to the DataFrame\n",
    "            SearchResultsData = pd.concat([SearchResultsData, pd.DataFrame(data=[[TrialNumber, str(batch_size_trial) + '-' + str(epochs_trial), 100 - MAPE]],\n",
    "                                                                    columns=['TrialNumber', 'Parameters', 'Accuracy'])], ignore_index=True)\n",
    "    \n",
    "    return SearchResultsData\n",
    "\n",
    "# Calling the function\n",
    "ResultsData = FunctionFindBestParams(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 6ms/step\n",
      "24/24 [==============================] - 0s 4ms/step\n",
      "Train - MAE: 105.2433523236872\n",
      "Train - RMSE: 159.41551681028741\n",
      "Test - MAE: 114.84861046448339\n",
      "Test - RMSE: 173.9458177115666\n"
     ]
    }
   ],
   "source": [
    "# Realizar predicciones en el conjunto de entrenamiento\n",
    "y_pred_train = model.predict(X_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "# Desescalar los valores predichos y los valores reales\n",
    "y_train_descaled = scaler.inverse_transform(y_train)\n",
    "y_pred_train_descaled = scaler.inverse_transform(y_pred_train)\n",
    "\n",
    "y_test_descaled = scaler.inverse_transform(y_test)\n",
    "y_pred_test_descaled = scaler.inverse_transform(y_pred_test)\n",
    "\n",
    "# Calcular métricas R^2, MAE y RMSE para el conjunto de entrenamiento\n",
    "r2_train = r2_score(y_train_descaled, y_pred_train_descaled)\n",
    "mae_train = mean_absolute_error(y_train_descaled, y_pred_train_descaled)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train_descaled, y_pred_train_descaled))\n",
    "\n",
    "# Calcular métricas R^2, MAE y RMSE para el conjunto de prueba\n",
    "r2_test = r2_score(y_test_descaled, y_pred_test_descaled)\n",
    "mae_test = mean_absolute_error(y_test_descaled, y_pred_test_descaled)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test_descaled, y_pred_test_descaled))\n",
    "\n",
    "# Imprimir los resultados para el conjunto de entrenamiento\n",
    "\n",
    "print(\"Train - MAE:\", mae_train)\n",
    "print(\"Train - RMSE:\", rmse_train)\n",
    "\n",
    "# Imprimir los resultados para el conjunto de prueba\n",
    "\n",
    "print(\"Test - MAE:\", mae_test)\n",
    "print(\"Test - RMSE:\", rmse_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
